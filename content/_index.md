---
header_brand: MetricRule
header_tagline_paragraph: Granular monitoring for ML services
header_button_cta:
  url: "#contact-form"
  title: Get in touch
header_button_more:
  url: "#monitor-models-in-production"
  title: Why?
teaser_image: ''

---

# Demo

{{< rawhtml >}}
<div style="position: relative; padding-bottom: 56.25%; height: 0;"><iframe src="https://www.loom.com/embed/09965b414cd84b7987ba5ca1e9619cf5" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe></div>
{{< /rawhtml >}}

***

Interested in being an alpha user?

{{< contact_form id="contact-form" placeholder_name="Name" placeholder_email="Email Address" placeholder_message="Message" button_label="Send ✉️">}}

***

# Monitor models in production

Building a great ML service is difficult. Managing it in production is doubly so.

MetricRule works with your serving stack to automatically create metrics for your services' inputs and outputs, so you can track and get alerted on bad model deployments, feature drifts, or unexpected data.

***

# Stay in touch

Sign up here to get very occasional updates from us. Don't worry, we hate spam too.

{{< newsletter_sign_up id="newsletter-sign-up-form" placeholder_email="Your Email" button_label="Sign up">}}
